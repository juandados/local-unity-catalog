name: unitycatalog

services:
  pyspark:
    build:
      context: pyspark
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
      - "4040:4040"  # For SparkUI
    volumes:
      - type: bind
        source: unitycatalog/etc/conf
        target: /opt/delta/etc/conf
      - type: volume
        source: unitycatalog
        target: /home/unitycatalog
    networks:
      - lakehouse_net
    command: tail -f /dev/null
  server:
    build:
      context: unitycatalog
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    volumes:
      - type: bind
        source: unitycatalog/etc/conf
        target: /opt/unitycatalog/etc/conf
      - type: volume
        source: unitycatalog
        target: /home/unitycatalog
    networks:
      - lakehouse_net
  
  ui:
    build:
      context: unitycatalog/ui/
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      - server
    networks:
      - lakehouse_net

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      MLFLOW_TRACKING_URI: http://0.0.0.0:5000
      MLFLOW_BACKEND_STORE_URI: /mlflow/mlruns
      MLFLOW_ARTIFACT_ROOT: /mlflow/mlruns
    volumes:
      - mlflow_data:/mlflow/mlruns
    networks:
      - lakehouse_net
    command: mlflow server --backend-store-uri /mlflow/mlruns --default-artifact-root /mlflow/mlruns --host 0.0.0.0

volumes:
  # Persist docker volume across container restarts
  unitycatalog:
  mlflow_data:

networks:
  lakehouse_net:
    external: true